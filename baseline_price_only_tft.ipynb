{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "771a9fca-2211-4a1a-af99-894500fe0f7d",
   "metadata": {},
   "source": [
    "## Price-Only Temporal Fusion Transformer — Baseline (Henry Hub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73576ac5-5b55-4517-845e-e6e6d5d2bc1a",
   "metadata": {},
   "source": [
    "### Imports and Configuration\n",
    "\n",
    "For the implemmentation of TFT, we are using pytorch. Tuning will be done using optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c14e10-46aa-4516-a0d2-8a7844fae35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, pickle, platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "import optuna\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.importance import get_param_importances\n",
    "from optuna.visualization.matplotlib import plot_optimization_history, plot_param_importances\n",
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "SEED = 1337\n",
    "pl.seed_everything(SEED, workers=True)\n",
    "torch.set_float32_matmul_precision(\"high\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e79461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "# SLURM / HPC: DataLoader + GPU config\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "SLURM_CPUS = int(os.environ.get(\"SLURM_CPUS_PER_TASK\", \"8\"))\n",
    "NUM_WORKERS = max(1, min(8, SLURM_CPUS - 1))\n",
    "PIN_MEMORY = torch.cuda.is_available()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "print(f\"SLURM_CPUS = {SLURM_CPUS}\")\n",
    "print(f\"NUM_WORKERS = {NUM_WORKERS}, PIN_MEMORY = {PIN_MEMORY}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import subprocess\n",
    "print(\"\\n--- nvidia-smi ---\")\n",
    "try:\n",
    "    print(subprocess.check_output([\"nvidia-smi\"]).decode(\"utf-8\"))\n",
    "except Exception as e:\n",
    "    print(\"nvidia-smi not available:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c8a6a2-e897-49f1-b974-50c4688b22ea",
   "metadata": {},
   "source": [
    "### Step 1 - Load Master CSV and Transform Data Set\n",
    "\n",
    "We load our master csv with all its columns, and transform the data set in memory to follow the format needed for PyTorch TFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edcf8ba-8c47-4c59-b988-d45fc1cc4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV = \"../numeric_data/henryhub_master.csv\"\n",
    "TARGET = \"price\"\n",
    "GROUP_COL = \"id\"\n",
    "\n",
    "# numeric features in our data set\n",
    "NUM_COLS = [\"storage_bcf\", \"production_bcf\", \"usd_index\", \"temp_c\", \"temp_max_c\", \"temp_min_c\"]\n",
    "\n",
    "def load_tft_ready_df(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path, parse_dates=[\"date\"])\n",
    "    df = df.sort_values([GROUP_COL, \"date\"]).reset_index(drop=True)\n",
    "\n",
    "    # group id as categorical\n",
    "    df[GROUP_COL] = df[GROUP_COL].astype(\"category\")\n",
    "\n",
    "    # target numeric\n",
    "    df[TARGET] = pd.to_numeric(df[TARGET], errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "    # covariates numeric\n",
    "    for c in NUM_COLS:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "    # TFT-required time index (0..N-1 per id)\n",
    "    df[\"time_idx\"] = df.groupby(GROUP_COL).cumcount().astype(np.int64)\n",
    "\n",
    "    # known future calendar covariates\n",
    "    df[\"dow\"] = df[\"date\"].dt.dayofweek.astype(\"category\")\n",
    "    df[\"month\"] = df[\"date\"].dt.month.astype(\"category\")\n",
    "\n",
    "    # sanity checks\n",
    "    assert df[[GROUP_COL, \"time_idx\"]].duplicated().sum() == 0\n",
    "    assert df[TARGET].isna().sum() == 0\n",
    "\n",
    "    return df\n",
    "\n",
    "data = load_tft_ready_df(CSV)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304671f6-ee88-4857-885a-cb2578fe4733",
   "metadata": {},
   "source": [
    "### Step 2 — Chronological Train/Validation/Test Split\n",
    "\n",
    "We split the dataset into train, validation, and test sets, to avoid leaking future information into training:\n",
    "- We first sort by date to guarantee chronological ordering.\n",
    "- We use a (70/15/15) split\n",
    "- We also compute:\n",
    "    - train_cutoff = last time_idx in the train block\n",
    "    - val_cutoff   = last time_idx in the validation block\n",
    "    \n",
    "These cutoffs are useful later when creating TFT datasets that require lookback context (e.g., 60 past days) at the start of validation/test windows. <br>\n",
    "Finally, we print the date ranges and time_idx cutoffs for sanity-checking that the split boundaries look correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d6fb7-532c-44eb-b48f-406cee060f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FRAC = 0.15\n",
    "VAL_FRAC  = 0.15\n",
    "LOOKBACK  = 60\n",
    "HORIZON   = 1\n",
    "\n",
    "# sort once\n",
    "data = data.sort_values(\"date\").reset_index(drop=True).copy()\n",
    "n = len(data)\n",
    "\n",
    "# sizes\n",
    "n_test     = int(n * TEST_FRAC)\n",
    "n_trainval = n - n_test\n",
    "n_val      = int(n_trainval * VAL_FRAC)\n",
    "n_train    = n_trainval - n_val\n",
    "\n",
    "# split\n",
    "train_data = data.iloc[:n_train].copy()\n",
    "val_data   = data.iloc[n_train:n_train + n_val].copy()\n",
    "test_data  = data.iloc[n_train + n_val:].copy()\n",
    "\n",
    "# cutoffs (last time_idx in each block)\n",
    "train_cutoff = int(train_data[\"time_idx\"].iloc[-1])\n",
    "val_cutoff   = int(val_data[\"time_idx\"].iloc[-1])\n",
    "\n",
    "print(f\"train {len(train_data)}: {train_data.date.min().date()} → {train_data.date.max().date()} | \"\n",
    "      f\"val {len(val_data)}: {val_data.date.min().date()} → {val_data.date.max().date()} | \"\n",
    "      f\"test {len(test_data)}: {test_data.date.min().date()} → {test_data.date.max().date()}\")\n",
    "print(f\"Cutoffs (time_idx): train_cutoff={train_cutoff}, val_cutoff={val_cutoff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed9432-3835-4b54-9e72-cdca3cba35d1",
   "metadata": {},
   "source": [
    "### Step 3 - Build TFT DataSets\n",
    "\n",
    "We convert id, dow, month into string-based pandas categoricals so pytorch-forecasting won’t complain about numeric categories.<br>\n",
    "common_args tells TimeSeriesDataSet what the time index is (time_idx), what the target is (price), what identifies the series (id), and what features are known (calendar) vs unknown (price history).<br>\n",
    "Uses GroupNormalizer so the target is normalized per series (no manual scaling step needed).<br>\n",
    "min_encoder_length = max_encoder_length = lookback forces every sample to use exactly LOOKBACK past days (consistent input size).<br>\n",
    "Builds train/val/test without leakage but with lookback context<br>\n",
    "Train uses data up to train_cutoff, and predictions start only once enough history exists (min_prediction_idx=lookback).<br>\n",
    "Validation includes earlier rows (so it has the last LOOKBACK train days available), but predictions start at train_cutoff + 1.<br>\n",
    "Test includes the full history for context, but predictions start at val_cutoff + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1afa93f-33bf-43cd-9e9d-2c4cb365fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tft_categoricals(df: pd.DataFrame,\n",
    "                            cat_cols=(\"id\", \"dow\", \"month\")) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    pytorch-forecasting (some versions) rejects categoricals whose categories are numeric.\n",
    "    Force numeric categoricals to string categories, then cast to 'category'.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for c in cat_cols:\n",
    "        if c not in df.columns:\n",
    "            continue\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            df[c] = df[c].astype(int).astype(str)\n",
    "        else:\n",
    "            df[c] = df[c].astype(str)\n",
    "        df[c] = df[c].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "def build_tft_datasets(\n",
    "    df: pd.DataFrame,\n",
    "    lookback: int,\n",
    "    horizon: int,\n",
    "    train_cutoff: int,\n",
    "    val_cutoff: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Version-compatible TFT dataset builder (no max_prediction_idx).\n",
    "    Enforces split boundaries by slicing df to <= cutoff and using min_prediction_idx.\n",
    "    Strict fixed lookback: min_encoder_length = max_encoder_length = lookback.\n",
    "    \"\"\"\n",
    "    df = prepare_tft_categoricals(df)\n",
    "\n",
    "    common_args = dict(\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"price\",\n",
    "        group_ids=[\"id\"],\n",
    "\n",
    "        max_encoder_length=lookback,\n",
    "        min_encoder_length=lookback,          # strict fixed lookback\n",
    "        max_prediction_length=horizon,\n",
    "\n",
    "        time_varying_known_reals=[\"time_idx\"],\n",
    "        time_varying_known_categoricals=list((\"dow\", \"month\")),\n",
    "        time_varying_unknown_reals=[\"price\"],\n",
    "\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        add_encoder_length=True,\n",
    "\n",
    "        target_normalizer=GroupNormalizer(groups=[\"id\"]),\n",
    "    )\n",
    "\n",
    "    train_ds = TimeSeriesDataSet(\n",
    "        df[df[\"time_idx\"] <= train_cutoff].copy(),\n",
    "        **common_args,\n",
    "        min_prediction_idx=lookback\n",
    "    )\n",
    "\n",
    "    val_ds = TimeSeriesDataSet(\n",
    "        df[df[\"time_idx\"] <= val_cutoff].copy(),\n",
    "        **common_args,\n",
    "        min_prediction_idx=train_cutoff + 1\n",
    "    )\n",
    "\n",
    "    test_ds = TimeSeriesDataSet(\n",
    "        df.copy(),\n",
    "        **common_args,\n",
    "        min_prediction_idx=val_cutoff + 1\n",
    "    )\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "# ---- usage ----\n",
    "train_ds, val_ds, test_ds = build_tft_datasets(\n",
    "    df=data,\n",
    "    lookback=LOOKBACK,\n",
    "    horizon=HORIZON,\n",
    "    train_cutoff=train_cutoff,\n",
    "    val_cutoff=val_cutoff,\n",
    ")\n",
    "\n",
    "print(\"Samples | train:\", len(train_ds), \"| val:\", len(val_ds), \"| test:\", len(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b348c-c444-4752-a0f8-98c7f6347207",
   "metadata": {},
   "source": [
    "### Step 4 - Dataloading\n",
    "\n",
    "Creates PyTorch DataLoaders for TFT training/evaluation <br>\n",
    "Converts train_ds, val_ds, and test_ds (TimeSeriesDataSets) into iterable batches that the Lightning trainer can consume.<br>\n",
    "Uses BATCH_SIZE = 64<br>\n",
    "Controls how many time-series samples are processed per gradient step (train) or per forward pass (val/test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b9dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = train_ds.to_dataloader(\n",
    "    train=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=(NUM_WORKERS > 0),\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "val_loader = val_ds.to_dataloader(\n",
    "    train=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=(NUM_WORKERS > 0),\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "test_loader = test_ds.to_dataloader(\n",
    "    train=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=(NUM_WORKERS > 0),\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21b3191",
   "metadata": {},
   "source": [
    "### Step 5 - One Run of TFT model for Verfication\n",
    "\n",
    "Runs one end-to-end TFT baseline training to confirm the whole pipeline works (datasets → dataloaders → model → training loop).<br>\n",
    "Builds a Temporal Fusion Transformer from train_ds using a small, fixed configuration (learning rate, hidden sizes, dropout) and QuantileLoss (outputs multiple quantile forecasts).<br>\n",
    "Trains with EarlyStopping on val_loss (stop if validation loss stops improving) for up to 60 epochs on the MPS GPU.<br>\n",
    "The output logs/model summary are just sanity checks that the model instantiated correctly and training is progressing, giving you a reference baseline before running hyperparameter experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888904dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = (0.05, 0.25, 0.5, 0.75, 0.95)\n",
    "\n",
    "tft_model = TemporalFusionTransformer.from_dataset(\n",
    "    train_ds,\n",
    "    learning_rate=1e-3,\n",
    "    hidden_size=32,\n",
    "    attention_head_size=4,\n",
    "    hidden_continuous_size=16,\n",
    "    dropout=0.1,\n",
    "    loss=QuantileLoss(list(quantiles)),\n",
    ")\n",
    "\n",
    "# --- fit ---\n",
    "callbacks = [EarlyStopping(monitor=\"val_loss\", patience=8, mode=\"min\")]\n",
    "\n",
    "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "devices = 1 if torch.cuda.is_available() else None\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=60,\n",
    "    accelerator=accelerator,\n",
    "    devices=devices,\n",
    "    callbacks=callbacks,\n",
    "    enable_checkpointing=False,\n",
    "    logger=False,\n",
    ")\n",
    "\n",
    "trainer.fit(tft_model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb5faf",
   "metadata": {},
   "source": [
    "### Step 6 -  Evaluate TFT on the Test Set (Quantiles → Point Forecast Metrics)\n",
    "\n",
    "Generate quantile forecasts from the TFT model<br>\n",
    "Convert quantiles into a single point forecast for comparability<br>\n",
    "evaluate_tft_baseline uses the P50 (median) quantile as the point prediction y_pred, enabling direct comparison to point-forecast models like the LSTM.\n",
    "Calculates MAE, RMSE, MAPE, and Directional Accuracy (whether the model predicts up/down movements correctly).<br>\n",
    "Plots Actual vs Predicted (P50), and (if available) shades the P05–P95 interval to visualise prediction uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tft_quantiles(model, loader, quantiles=(0.05, 0.25, 0.5, 0.75, 0.95)):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      preds_q: np.ndarray [N, H, Q]  (H=1 in your setup)\n",
    "      y_true:  np.ndarray [N]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    preds_q = model.predict(loader, mode=\"quantiles\")\n",
    "    # robust to torch/numpy return types\n",
    "    if hasattr(preds_q, \"detach\"):\n",
    "        preds_q = preds_q.detach().cpu().numpy()\n",
    "    else:\n",
    "        preds_q = np.asarray(preds_q)\n",
    "\n",
    "    actuals = []\n",
    "    for x, y in loader:\n",
    "        yy = y[0] if isinstance(y, (tuple, list)) else y\n",
    "        actuals.append(yy.detach().cpu().numpy())\n",
    "    y_true = np.concatenate(actuals, axis=0).reshape(-1)\n",
    "\n",
    "    return preds_q, y_true\n",
    "\n",
    "\n",
    "def evaluate_tft_baseline(\n",
    "    model,\n",
    "    test_loader,\n",
    "    quantiles=(0.05, 0.25, 0.5, 0.75, 0.95),\n",
    "    plot=True,\n",
    "    save_path=None,          # <-- NEW: e.g. \"runs/.../pred_vs_actual.png\"\n",
    "    dpi=150,\n",
    "    title=\"TFT Next-Day Forecast — Test Set\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes MAE/RMSE/MAPE/Directional Accuracy using P50 as point forecast.\n",
    "    If plot=True:\n",
    "      - shows the plot (if save_path is None)\n",
    "      - or saves to save_path (and closes) if save_path is provided\n",
    "    Returns metrics dict + y_true/y_pred for saving elsewhere if desired.\n",
    "    \"\"\"\n",
    "    preds_q, y_true = predict_tft_quantiles(model, test_loader, quantiles=quantiles)\n",
    "\n",
    "    q_list = list(quantiles)\n",
    "    if 0.5 not in q_list:\n",
    "        raise ValueError(\"Quantiles must include 0.5 for P50 point forecast.\")\n",
    "    q50_idx = q_list.index(0.5)\n",
    "\n",
    "    # H=1 => [N, Q]\n",
    "    y_pred_q = preds_q[:, 0, :]\n",
    "    y_pred = y_pred_q[:, q50_idx]\n",
    "\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    mape = float(np.mean(np.abs((y_true - y_pred) / np.clip(np.abs(y_true), 1e-6, None))) * 100)\n",
    "\n",
    "    true_dir = np.sign(np.diff(y_true))\n",
    "    pred_dir = np.sign(np.diff(y_pred))\n",
    "    da = float((true_dir == pred_dir).mean() * 100)\n",
    "\n",
    "    if plot:\n",
    "        x = np.arange(len(y_pred))\n",
    "        # optional band if P05/P95 exist\n",
    "        if 0.05 in q_list and 0.95 in q_list:\n",
    "            qlo = y_pred_q[:, q_list.index(0.05)]\n",
    "            qhi = y_pred_q[:, q_list.index(0.95)]\n",
    "        else:\n",
    "            qlo = qhi = None\n",
    "\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(y_true, label=\"Actual\")\n",
    "        plt.plot(y_pred, label=\"Pred (P50)\")\n",
    "        if qlo is not None:\n",
    "            plt.fill_between(x, qlo, qhi, alpha=0.2, label=\"P05–P95\")\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_path is not None:\n",
    "            plt.savefig(save_path, dpi=dpi)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    print(f\"MAE              : {mae:.4f}\")\n",
    "    print(f\"RMSE             : {rmse:.4f}\")\n",
    "    print(f\"MAPE             : {mape:.2f}%\")\n",
    "    print(f\"Directional Acc. : {da:.2f}%\")\n",
    "\n",
    "    return {\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAPE\": mape,\n",
    "        \"Directional_Accuracy\": da,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred_p50\": y_pred,\n",
    "    }\n",
    "\n",
    "tft_test_metrics = evaluate_tft_baseline(\n",
    "    model=tft_model,\n",
    "    test_loader=test_loader,\n",
    "    quantiles=(0.05, 0.25, 0.5, 0.75, 0.95),\n",
    "    plot=True\n",
    ")\n",
    "print(tft_test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beee4b60",
   "metadata": {},
   "source": [
    "### Step 7 - HyperParameter Tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ea69f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- locked-in spec ----\n",
    "QUANTILES = (0.05, 0.25, 0.5, 0.75, 0.95)\n",
    "MAX_EPOCHS = 60\n",
    "PATIENCE = 8\n",
    "\n",
    "# ---- search space ----\n",
    "ENCODER_CHOICES = [20, 30, 45, 60, 90, 120, 180]\n",
    "BATCH_CHOICES   = [32, 64, 128, 256]\n",
    "CLIP_CHOICES    = [0.1, 0.25, 0.5, 1.0, 2.0]\n",
    "HIDDEN_CHOICES  = [16, 24, 32, 48, 64, 96, 128, 192]\n",
    "HEAD_CHOICES    = [1, 2, 4, 8]\n",
    "HCONT_CHOICES   = [8, 16, 24, 32, 48, 64]\n",
    "LSTM_LAYER_CHOICES = [1, 2, 3]\n",
    "\n",
    "# cache datasets by lookback to avoid rebuilding for repeated encoder lengths\n",
    "_DATASET_CACHE = {}\n",
    "\n",
    "class OptunaPruningCallback(pl.Callback):\n",
    "    def __init__(self, trial, monitor=\"val_loss\"):\n",
    "        super().__init__()\n",
    "        self.trial = trial\n",
    "        self.monitor = monitor\n",
    "        self.best = float(\"inf\")\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        val = trainer.callback_metrics.get(self.monitor)\n",
    "        if val is None:\n",
    "            return\n",
    "        score = float(val.detach().cpu().item()) if hasattr(val, \"detach\") else float(val)\n",
    "\n",
    "        self.best = min(self.best, score)           # <-- keep best\n",
    "        self.trial.report(score, step=trainer.current_epoch)\n",
    "        if self.trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "\n",
    "def _valid_heads(hidden_size: int):\n",
    "    hs = [h for h in HEAD_CHOICES if (hidden_size % h == 0)]\n",
    "    return hs if hs else [1]\n",
    "\n",
    "def _valid_hidden_cont(hidden_size: int):\n",
    "    hc = [c for c in HCONT_CHOICES if c <= hidden_size]\n",
    "    return hc if hc else [max(8, min(16, hidden_size))]\n",
    "\n",
    "def _clamp_hidden_cont(hidden_cont: int, hidden_size: int) -> int:\n",
    "    \"\"\"Clamp hidden_continuous_size to be <= hidden_size (TFT requirement).\"\"\"\n",
    "    return min(hidden_cont, hidden_size)\n",
    "\n",
    "\n",
    "def _get_datasets_for_lookback(lookback: int):\n",
    "    \"\"\"\n",
    "    Uses your existing build_tft_datasets(...) and global:\n",
    "      - data, HORIZON, train_cutoff, val_cutoff\n",
    "    Strict lookback is enforced inside build_tft_datasets (min=max=lookback).\n",
    "    \"\"\"\n",
    "    if lookback in _DATASET_CACHE:\n",
    "        return _DATASET_CACHE[lookback]\n",
    "\n",
    "    train_ds, val_ds, test_ds = build_tft_datasets(\n",
    "        df=data,\n",
    "        lookback=lookback,\n",
    "        horizon=HORIZON,\n",
    "        train_cutoff=train_cutoff,\n",
    "        val_cutoff=val_cutoff,\n",
    "    )\n",
    "    _DATASET_CACHE[lookback] = (train_ds, val_ds, test_ds)\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "def _make_loaders(train_ds, val_ds, test_ds, batch_size: int, num_workers: int = NUM_WORKERS):\n",
    "    train_loader = train_ds.to_dataloader(\n",
    "        train=True,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        persistent_workers=(num_workers > 0),\n",
    "        pin_memory=PIN_MEMORY,\n",
    "    )\n",
    "    val_loader = val_ds.to_dataloader(\n",
    "        train=False,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        persistent_workers=(num_workers > 0),\n",
    "        pin_memory=PIN_MEMORY,\n",
    "    )\n",
    "    test_loader = test_ds.to_dataloader(\n",
    "        train=False,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        persistent_workers=(num_workers > 0),\n",
    "        pin_memory=PIN_MEMORY,\n",
    "    )\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "def build_tft_model_from_trial(trial: optuna.Trial, train_ds, lookback: int):\n",
    "    \"\"\"\n",
    "    Build TFT model from trial. `lookback` is passed in (already sampled in objective)\n",
    "    to avoid double-sampling max_encoder_length.\n",
    "    \n",
    "    NOTE: Uses fixed categorical choices for attention_head_size and hidden_continuous_size\n",
    "    to avoid Optuna's \"dynamic value space\" error, then clamps values post-sampling.\n",
    "    \"\"\"\n",
    "    # Store lookback as a user attribute (not re-sampled) so it shows in trial results\n",
    "    trial.set_user_attr(\"max_encoder_length\", lookback)\n",
    "\n",
    "    # batch/optim\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", BATCH_CHOICES)\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-4, 3e-3, log=True)\n",
    "    clip = trial.suggest_categorical(\"gradient_clip_val\", CLIP_CHOICES)\n",
    "\n",
    "    use_wd = trial.suggest_categorical(\"use_weight_decay\", [False, True])\n",
    "    wd = trial.suggest_float(\"weight_decay\", 1e-7, 1e-3, log=True) if use_wd else 0.0\n",
    "\n",
    "    # capacity - use FIXED choices to avoid Optuna dynamic value space error\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", HIDDEN_CHOICES)\n",
    "    \n",
    "    # Sample from fixed lists, then clamp/filter post-hoc\n",
    "    head_size_raw = trial.suggest_categorical(\"attention_head_size\", HEAD_CHOICES)\n",
    "    # Ensure head_size divides hidden_size; fall back to 1 if not\n",
    "    head_size = head_size_raw if (hidden_size % head_size_raw == 0) else 1\n",
    "    \n",
    "    hidden_cont_raw = trial.suggest_categorical(\"hidden_continuous_size\", HCONT_CHOICES)\n",
    "    # Clamp hidden_continuous_size to be <= hidden_size\n",
    "    hidden_cont = _clamp_hidden_cont(hidden_cont_raw, hidden_size)\n",
    "    \n",
    "    dropout     = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lstm_layers = trial.suggest_categorical(\"lstm_layers\", LSTM_LAYER_CHOICES)\n",
    "\n",
    "    loss = QuantileLoss(list(QUANTILES))\n",
    "\n",
    "    # build model - pass weight_decay directly to TFT (not via optimizer_params)\n",
    "    model_kwargs = dict(\n",
    "        learning_rate=lr,\n",
    "        hidden_size=hidden_size,\n",
    "        attention_head_size=head_size,\n",
    "        hidden_continuous_size=hidden_cont,\n",
    "        dropout=dropout,\n",
    "        loss=loss,\n",
    "    )\n",
    "\n",
    "    # these exist in most pytorch-forecasting versions; keep robust\n",
    "    extra_kwargs = dict(\n",
    "        lstm_layers=lstm_layers,\n",
    "        optimizer=\"adam\",\n",
    "    )\n",
    "    # Pass weight_decay directly to TFT (not via optimizer_params to avoid duplication)\n",
    "    if wd > 0:\n",
    "        extra_kwargs[\"weight_decay\"] = wd\n",
    "\n",
    "    try:\n",
    "        model = TemporalFusionTransformer.from_dataset(train_ds, **model_kwargs, **extra_kwargs)\n",
    "    except TypeError:\n",
    "        # fallback if lstm_layers / optimizer not supported in your version\n",
    "        model = TemporalFusionTransformer.from_dataset(train_ds, **model_kwargs)\n",
    "\n",
    "    hparams = dict(\n",
    "        max_encoder_length=lookback,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=lr,\n",
    "        gradient_clip_val=clip,\n",
    "        weight_decay=wd,\n",
    "        hidden_size=hidden_size,\n",
    "        attention_head_size=head_size,\n",
    "        hidden_continuous_size=hidden_cont,\n",
    "        dropout=dropout,\n",
    "        lstm_layers=lstm_layers,\n",
    "        quantiles=list(QUANTILES),\n",
    "    )\n",
    "    return model, hparams\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    pl.seed_everything(SEED, workers=True)\n",
    "\n",
    "    # sample lookback ONCE here\n",
    "    lookback = trial.suggest_categorical(\"max_encoder_length\", ENCODER_CHOICES)\n",
    "    train_ds, val_ds, test_ds = _get_datasets_for_lookback(lookback)\n",
    "\n",
    "    # build model (lookback passed in to avoid double-sampling)\n",
    "    model, hparams = build_tft_model_from_trial(trial, train_ds=train_ds, lookback=lookback)\n",
    "\n",
    "    batch_size = hparams[\"batch_size\"]\n",
    "    train_loader, val_loader, _ = _make_loaders(train_ds, val_ds, test_ds, batch_size=batch_size, num_workers=NUM_WORKERS)\n",
    "\n",
    "    # callbacks: early stopping + pruning (track best val_loss)\n",
    "    prune_cb = OptunaPruningCallback(trial, monitor=\"val_loss\")\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=PATIENCE, mode=\"min\"),\n",
    "        prune_cb,\n",
    "    ]\n",
    "\n",
    "    clip_val = hparams.get(\"gradient_clip_val\", 0.5)\n",
    "    \n",
    "    accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "    devices = 1 if torch.cuda.is_available() else None\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=MAX_EPOCHS,\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        gradient_clip_val=clip_val,\n",
    "        enable_checkpointing=False,\n",
    "        callbacks=callbacks,\n",
    "        logger=False,\n",
    "        enable_progress_bar=False,\n",
    "        enable_model_summary=False,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    best_val = prune_cb.best\n",
    "\n",
    "    # cleanup\n",
    "    del trainer, model\n",
    "    gc.collect()\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return float(best_val)\n",
    "\n",
    "\n",
    "# ---- Study runner with SQLite storage for resumable runs ----\n",
    "STUDY_NAME = \"price_only_henryhub_parameter_optimisation_v1\"\n",
    "STORAGE_URL = \"sqlite:///optuna_gas_tft_phase1.db\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=STUDY_NAME,\n",
    "    storage=STORAGE_URL,\n",
    "    load_if_exists=True,          # <-- resume from previous runs if DB exists\n",
    "    direction=\"minimize\",\n",
    "    sampler=TPESampler(seed=42),\n",
    "    pruner=MedianPruner(n_warmup_steps=5),\n",
    ")\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "# set as high as you want (you said thousands)\n",
    "N_TRIALS = 1000\n",
    "study.optimize(objective, n_trials=N_TRIALS, gc_after_trial=True)\n",
    "\n",
    "print(\"Best value (val_loss):\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34277d52",
   "metadata": {},
   "source": [
    "### Step 8 - Save Optuna Search Results (Timestamped Run Folder)\n",
    "\n",
    "Creates a unique output directory for this run using the current UTC timestamp, e.g. saved_tft_models/20260111-154233_price_only_tft/, so results don’t overwrite previous runs.\n",
    "Exports the full Optuna trial log to optuna_trials.csv (trial id, state, objective value, sampled hyperparameters).\n",
    "Saves the best trial summary to best_params.json (best value + best hyperparameters).\n",
    "Generates and saves Optuna plots:\n",
    "- optuna_history.png (objective over trials)\n",
    "- optuna_param_importances.png + optuna_param_importances.json (hyperparameter importance), or an error file if importances can’t be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481428f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _utc_run_dir(base_dir=\"saved_tft_models\", run_name=\"price_only_tft\"):\n",
    "    ts = datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%S\")\n",
    "    out_dir = os.path.join(base_dir, f\"{ts}_{run_name}\".replace(\" \", \"_\"))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    return out_dir\n",
    "\n",
    "def save_optuna_study_artifacts(study: optuna.Study, out_dir: str):\n",
    "    \"\"\"Save trials table + best params + basic Optuna plots (PNG).\"\"\"\n",
    "    # trials dataframe\n",
    "    df = study.trials_dataframe(attrs=(\"number\", \"state\", \"value\", \"params\", \"user_attrs\"))\n",
    "    df.to_csv(os.path.join(out_dir, \"optuna_trials.csv\"), index=False)\n",
    "\n",
    "    # best params\n",
    "    with open(os.path.join(out_dir, \"best_params.json\"), \"w\") as f:\n",
    "        json.dump({\"best_value\": study.best_value, \"best_params\": study.best_params}, f, indent=2)\n",
    "\n",
    "    # optimization history plot\n",
    "    fig1 = plot_optimization_history(study)\n",
    "    fig1.figure.savefig(os.path.join(out_dir, \"optuna_history.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close(fig1.figure)\n",
    "\n",
    "    # param importances plot (can fail if too few completed trials)\n",
    "    try:\n",
    "        fig2 = plot_param_importances(study)\n",
    "        fig2.figure.savefig(os.path.join(out_dir, \"optuna_param_importances.png\"), dpi=150, bbox_inches=\"tight\")\n",
    "        plt.close(fig2.figure)\n",
    "\n",
    "        imp = get_param_importances(study)\n",
    "        with open(os.path.join(out_dir, \"optuna_param_importances.json\"), \"w\") as f:\n",
    "            json.dump(imp, f, indent=2)\n",
    "    except Exception as e:\n",
    "        with open(os.path.join(out_dir, \"optuna_param_importances_error.txt\"), \"w\") as f:\n",
    "            f.write(str(e))\n",
    "\n",
    "out_dir = _utc_run_dir()\n",
    "save_optuna_study_artifacts(study, out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4b91fd",
   "metadata": {},
   "source": [
    "### Step 9 - Save Best TFT Run Artifacts (Checkpoint + Metrics + Plots)\n",
    "\n",
    "Trains the final TFT model using the best Optuna hyperparameters, then saves all outputs to the timestamped out_dir run folder:\n",
    "- Best model checkpoint (lowest val_loss): out_dir/checkpoints/best-*.ckpt\n",
    "- Training logs (epoch metrics): out_dir/logs/metrics.csv\n",
    "- Test evaluation plot: out_dir/pred_vs_actual.png\n",
    "- Final test metrics + checkpoint path: out_dir/final_test_metrics.json\n",
    "- Validation-loss training curve: out_dir/training_curve_val_loss.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tft_from_best_params(train_ds, best_params: dict, quantiles=(0.05, 0.25, 0.5, 0.75, 0.95)):\n",
    "    \"\"\"Build TFT robustly across pytorch-forecasting versions.\"\"\"\n",
    "    loss = QuantileLoss(list(quantiles))\n",
    "\n",
    "    # required / core knobs\n",
    "    model_kwargs = dict(\n",
    "        learning_rate=float(best_params[\"learning_rate\"]),\n",
    "        hidden_size=int(best_params[\"hidden_size\"]),\n",
    "        attention_head_size=int(best_params[\"attention_head_size\"]),\n",
    "        hidden_continuous_size=int(best_params[\"hidden_continuous_size\"]),\n",
    "        dropout=float(best_params[\"dropout\"]),\n",
    "        loss=loss,\n",
    "    )\n",
    "\n",
    "    # optional knobs (might not exist in every version)\n",
    "    extra_kwargs = {}\n",
    "    if \"lstm_layers\" in best_params:\n",
    "        extra_kwargs[\"lstm_layers\"] = int(best_params[\"lstm_layers\"])\n",
    "\n",
    "    # weight decay - pass directly to TFT (not via optimizer_params to avoid duplication)\n",
    "    wd = float(best_params.get(\"weight_decay\", 0.0))\n",
    "    if wd > 0:\n",
    "        extra_kwargs[\"weight_decay\"] = wd\n",
    "\n",
    "    # try with extras first; fallback if your version doesn't support them\n",
    "    try:\n",
    "        model = TemporalFusionTransformer.from_dataset(train_ds, **model_kwargs, **extra_kwargs)\n",
    "    except TypeError:\n",
    "        model = TemporalFusionTransformer.from_dataset(train_ds, **model_kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "def fit_best_tft(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    out_dir: str,\n",
    "    max_epochs=60,\n",
    "    patience=8,\n",
    "    gradient_clip_val=0.5,\n",
    "):\n",
    "    \"\"\"Train best TFT once, save best checkpoint, and log epoch metrics to CSV.\"\"\"\n",
    "    logger = CSVLogger(save_dir=out_dir, name=\"logs\")\n",
    "\n",
    "    ckpt = ModelCheckpoint(\n",
    "        dirpath=os.path.join(out_dir, \"checkpoints\"),\n",
    "        filename=\"best-{epoch:02d}-{val_loss:.6f}\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=1,\n",
    "    )\n",
    "\n",
    "    accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "    devices = 1 if torch.cuda.is_available() else None\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        gradient_clip_val=float(gradient_clip_val),\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\"),\n",
    "            ckpt,\n",
    "        ],\n",
    "        logger=logger,\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=True,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    best_path = ckpt.best_model_path\n",
    "    best_score = ckpt.best_model_score\n",
    "    best_score = float(best_score.detach().cpu().item()) if best_score is not None else None\n",
    "    return trainer, best_path, best_score, logger.log_dir\n",
    "\n",
    "def save_training_curves_from_csv(log_dir: str, out_dir: str):\n",
    "    \"\"\"Plot train/val curves from Lightning CSVLogger metrics.csv.\"\"\"\n",
    "    metrics_path = os.path.join(log_dir, \"metrics.csv\")\n",
    "    if not os.path.exists(metrics_path):\n",
    "        return\n",
    "\n",
    "    m = pd.read_csv(metrics_path)\n",
    "    # Lightning stores metrics across steps; keep one point per epoch where val_loss exists\n",
    "    if \"epoch\" not in m.columns:\n",
    "        return\n",
    "\n",
    "    # plot val_loss vs epoch\n",
    "    if \"val_loss\" in m.columns:\n",
    "        vv = m.dropna(subset=[\"val_loss\"]).groupby(\"epoch\", as_index=False)[\"val_loss\"].last()\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(vv[\"epoch\"], vv[\"val_loss\"], label=\"val_loss\")\n",
    "        plt.title(\"Training Curve — val_loss\")\n",
    "        plt.xlabel(\"epoch\"); plt.ylabel(\"val_loss\")\n",
    "        plt.legend(); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_dir, \"training_curve_val_loss.png\"), dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "# 2) rebuild datasets/loaders using best lookback + best batch_size\n",
    "best = study.best_params\n",
    "best_lookback = int(best[\"max_encoder_length\"])\n",
    "best_batch    = int(best[\"batch_size\"])\n",
    "\n",
    "train_ds_best, val_ds_best, test_ds_best = build_tft_datasets(\n",
    "    df=data,\n",
    "    lookback=best_lookback,\n",
    "    horizon=HORIZON,\n",
    "    train_cutoff=train_cutoff,\n",
    "    val_cutoff=val_cutoff,\n",
    ")\n",
    "\n",
    "train_loader_best = train_ds_best.to_dataloader(\n",
    "    train=True,\n",
    "    batch_size=best_batch,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=(NUM_WORKERS > 0),\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "val_loader_best = val_ds_best.to_dataloader(\n",
    "    train=False,\n",
    "    batch_size=best_batch,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=(NUM_WORKERS > 0),\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "test_loader_best = test_ds_best.to_dataloader(\n",
    "    train=False,\n",
    "    batch_size=best_batch,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=(NUM_WORKERS > 0),\n",
    "    pin_memory=PIN_MEMORY,\n",
    ")\n",
    "\n",
    "# 3) build + fit best model once (early stop on val_loss, save checkpoint)\n",
    "best_model = build_tft_from_best_params(train_ds_best, best, quantiles=QUANTILES)\n",
    "\n",
    "trainer, best_ckpt_path, best_val, log_dir = fit_best_tft(\n",
    "    model=best_model,\n",
    "    train_loader=train_loader_best,\n",
    "    val_loader=val_loader_best,\n",
    "    out_dir=out_dir,\n",
    "    max_epochs=60,\n",
    "    patience=8,\n",
    "    gradient_clip_val=float(best.get(\"gradient_clip_val\", 0.5)),\n",
    ")\n",
    "\n",
    "print(\"Best checkpoint:\", best_ckpt_path)\n",
    "print(\"Best val_loss:\", best_val)\n",
    "\n",
    "# 4) evaluate on test and save plot/metrics\n",
    "# PyTorch 2.6+ changed weights_only default to True, but Lightning checkpoints\n",
    "# contain custom objects (pandas DataFrames, etc.) that require weights_only=False\n",
    "# We monkey-patch torch.load to force weights_only=False for checkpoint loading\n",
    "_original_torch_load = torch.load\n",
    "def _patched_load(*args, **kwargs):\n",
    "    kwargs[\"weights_only\"] = False  # Force weights_only=False\n",
    "    return _original_torch_load(*args, **kwargs)\n",
    "torch.load = _patched_load\n",
    "\n",
    "best_model = TemporalFusionTransformer.load_from_checkpoint(best_ckpt_path)\n",
    "\n",
    "# Restore original torch.load\n",
    "torch.load = _original_torch_load\n",
    "\n",
    "metrics = evaluate_tft_baseline(\n",
    "    model=best_model,\n",
    "    test_loader=test_loader_best,\n",
    "    quantiles=QUANTILES,\n",
    "    plot=True,\n",
    "    save_path=os.path.join(out_dir, \"pred_vs_actual.png\"),\n",
    ")\n",
    "\n",
    "with open(os.path.join(out_dir, \"final_test_metrics.json\"), \"w\") as f:\n",
    "    json.dump(\n",
    "        {\"best_val_loss\": best_val, \"best_checkpoint\": best_ckpt_path, \"test_metrics\": metrics},\n",
    "        f,\n",
    "        indent=2,\n",
    "        default=lambda x: x.tolist() if hasattr(x, \"tolist\") else str(x),\n",
    "    )\n",
    "\n",
    "# 5) save training curves\n",
    "save_training_curves_from_csv(log_dir, out_dir)\n",
    "\n",
    "print(\"Test metrics:\", metrics)\n",
    "print(\"Saved best-run artifacts to:\", out_dir)\n",
    "\n",
    "# cleanup GPU memory\n",
    "try:\n",
    "    torch.cuda.empty_cache()\n",
    "except Exception:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
